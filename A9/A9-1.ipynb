{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: Hypothesis Testing (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, we cannot get the full population but only a sample. If we derive an interesting result from a sample, how likely can we derive the same result from the entire population? In other words, we want to know whether this result is a true finding or it just happens in the sample by chance. Hypothesis testing aims to answer this fundamental question. \n",
    "\n",
    "\n",
    "**Hypothesis Testing**\n",
    "1. Why A/B testing?  \n",
    "2. What is a permutation test? How to implement it?\n",
    "3. What is p-value? How to avoid p-hacking? \n",
    "4. What is a chi-squared test? How to implement it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. A/B Testing\n",
    "> Acknowledgment: Thank [Greg Baker](http://www.cs.sfu.ca/~ggbaker/) for helping me to prepare this task.\n",
    "\n",
    "A very common technique to evaluate changes in a user interface is A/B testing: show some users interface A, some interface B, and then look to see if one performs better than the other.\n",
    "\n",
    "Suppose I started an A/B test on CourSys. Here are the two interfaces that I want to compare with. I want to know whether a good placeholder in the search box can attract more users to use the `search` feature.\n",
    "\n",
    "\n",
    "![](img/ab-testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided [searchlog.json](searchlog.json) has information about users' usage. The question I was interested in: is the number of searches per user different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we need to first pick up a **test statistic** to quantify how good an interface is. Here, we choose \"the search_count mean\". \n",
    "\n",
    "Please write the code to compute **the difference of the search_count means between interface A and Interface B.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in search_count means between interface A and B is: 0.13500569535052287\n"
     ]
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json(\"searchlog.json\", lines=True)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "search_counts_A = df.loc[df['search_ui'] == 'A', 'search_count']\n",
    "search_counts_B = df.loc[df['search_ui'] == 'B', 'search_count']\n",
    "\n",
    "# Calculate the mean search_count for interface A\n",
    "mean_search_count_A = search_counts_A.mean()\n",
    "\n",
    "# Calculate the mean search_count for interface B\n",
    "mean_search_count_B = search_counts_B.mean()\n",
    "\n",
    "# Calculate the difference in search_count means\n",
    "diff_mean = mean_search_count_B - mean_search_count_A\n",
    "\n",
    "print(f\"The difference in search_count means between interface A and B is: {diff_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we find that the mean value increased by 0.135. Then, we wonder whether this result is just caused by random variation. \n",
    "\n",
    "We define the Null Hypothesis as\n",
    " * The difference in search_count mean between Interface A and Interface B is caused by random variation. \n",
    " \n",
    "Then the next job is to check whether we can reject the null hypothesis or not. If it does, we can adopt the alternative explanation:\n",
    " * The difference in search_count mean  between Interface A and Interface B is caused by the design differences between the two.\n",
    "\n",
    "We compute the p-value of the observed result. If p-value is low (e.g., <0.01), we can reject the null hypothesis, and adopt  the alternative explanation.  \n",
    "\n",
    "Please implement a permutation test (numSamples = 10000) to compute the p-value. Note that you are NOT allowed to use an implementation in an existing library. You have to implement it by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is 0.1268\n"
     ]
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "numSamples = 10000\n",
    "diff_means = np.zeros(numSamples)\n",
    "\n",
    "\n",
    "for i in range(numSamples):\n",
    "    # Concatenate the search_count values and shuffle them randomly\n",
    "    concat_search_counts = np.concatenate([search_counts_A, search_counts_B])\n",
    "    np.random.shuffle(concat_search_counts)\n",
    "\n",
    "    # Rearrange search_count values into two groups\n",
    "    perm_search_counts_A = concat_search_counts[:len(search_counts_A)]\n",
    "    perm_search_counts_B = concat_search_counts[len(search_counts_A):]\n",
    "\n",
    "    diff_means[i] = np.mean(perm_search_counts_A) - np.mean(perm_search_counts_B)\n",
    "\n",
    "p_value = p_value = np.sum(diff_means >= diff_mean) / numSamples\n",
    "print(f\"The p-value is {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to use the same dataset to do another A/B testing. We suspect that instructors are the ones who can get more useful information from the search feature, so perhaps non-instructors didn't touch the search feature because it was genuinely not relevant to them.\n",
    "\n",
    "So we decide to repeat the above analysis looking only at instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. If using the same dataset to do this analysis, do you feel like we're p-hacking? If so, what can we do with it?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** Yes, this is p-hacking. Since we are keeping doing analysis on the same data sets. We could decrease the level of signficance (eg. alpha/2), and it is important to plan the analysis and clarify the hypothesis testing in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Chi-squared Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tens of different hypothesis testing methods. It's impossible to cover all of them in one week. Given that this is an important topic in statistics, I highly recommend using your free time to learn some other popular ones such as <a href=\"https://en.wikipedia.org/wiki/Chi-squared_test\">Chi-squared test</a>, <a href=\"https://en.wikipedia.org/wiki/G-test\">G-test</a>, <a href=\"https://en.wikipedia.org/wiki/Student%27s_t-test\">T-test</a>, and <a href=\"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\">Mannâ€“Whitney U test</a>.\n",
    "\n",
    "On the searchlog dataset, there are two categorical columns: `is_instructor` and `search_ui`. In Task D, your job is to first learn how a Chi-Squired test works by yourself and then use it to test whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please write code to compute the Chi-squared stat. Note that you are **not** allowed to call an existing function (e.g., stats.chi2, chi2_contingency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chi-squred value is 0.6731740891275046\n",
      "The degree of freedom is 1\n"
     ]
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(data['is_instructor'], data['search_ui'])\n",
    "\n",
    "# Compute the expected frequencies for each cell in the contingency table\n",
    "row_totals = contingency_table.sum(axis=1)\n",
    "col_totals = contingency_table.sum(axis=0)\n",
    "total = sum(row_totals)\n",
    "expected = np.outer(row_totals, col_totals) / total\n",
    "\n",
    "# Compute the chi-squared statistic\n",
    "observed = contingency_table.to_numpy()\n",
    "chi_squared = np.sum((observed - expected)**2 / expected)\n",
    "\n",
    "# Compute the degrees of freedom\n",
    "degrees_of_freedom = (len(row_totals)-1) * (len(col_totals)-1)\n",
    "\n",
    "print(f\"The chi-squred value is {chi_squared}\")\n",
    "print(f\"The degree of freedom is {degrees_of_freedom}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain how to use Chi-squared test to determine whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** Once we have calculated the Chi-squared statistic, we can use a Chi-squared distribution table to find the p-value associated with the test. The p-value is the probability of observing a test statistic as extreme as the one calculated from our data, assuming that the null hypothesis is true. We find the row which corresponds to the problem degree of freedom [=1] and find the column for level of confidence (usually 0.05). This value equals to 3.841 in this sample. \n",
    "\n",
    "If the p-value is less than our chosen significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables. If the p-value is greater than our chosen significance level, we fail to reject the null hypothesis and conclude that there is insufficient evidence to suggest a significant association between the two variables. Here, we find that 0.67317 < 3.841, therefore, we fail to reject the null hypothesis, then `is_instructor` and `search_ui` are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in this notebook, and submit it to the CourSys activity Assignment 9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
